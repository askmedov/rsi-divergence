{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from numba import jit\n",
    "import pickle\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data provided must be in the following form:\n",
    "\n",
    "datesA closeA datesB closeB datesC closeC ...\n",
    "\n",
    "This method prevents survivorship bias if one just selected current members of S&P 500 index (or any other index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = pd.read_parquet('spx_close.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lyb</th>\n",
       "      <th>date.1</th>\n",
       "      <th>axp</th>\n",
       "      <th>date.2</th>\n",
       "      <th>vz</th>\n",
       "      <th>date.3</th>\n",
       "      <th>avgo</th>\n",
       "      <th>date.4</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>date.1008</th>\n",
       "      <th>667517q</th>\n",
       "      <th>date.1009</th>\n",
       "      <th>300583q</th>\n",
       "      <th>date.1010</th>\n",
       "      <th>285939q</th>\n",
       "      <th>date.1011</th>\n",
       "      <th>1727044d</th>\n",
       "      <th>date.1012</th>\n",
       "      <th>827663q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>59.17</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>45.8828</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>53.7247</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>100.09</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>40.188</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>59.6250</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>84.1250</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>44.0625</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>63.8125</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>86.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>57.64</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>44.1504</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>51.9880</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>98.49</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>40.125</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>56.6250</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>80.8750</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>43.5000</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>64.6875</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>79.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>58.41</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>42.9650</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>53.7247</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>96.25</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>42.625</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>54.1250</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>79.9375</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>44.1875</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>65.5000</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>77.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>59.14</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>43.8404</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>53.1085</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>98.85</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>43.063</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>53.9375</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>80.6250</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>47.2500</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>65.7500</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>59.74</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>44.4786</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>52.7163</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>103.79</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>44.313</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>58.0000</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>80.4375</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>49.9375</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>65.7500</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    lyb     date.1      axp     date.2       vz     date.3  \\\n",
       "0 2013-01-02  59.17 2000-01-03  45.8828 2000-01-03  53.7247 2015-01-02   \n",
       "1 2013-01-03  57.64 2000-01-04  44.1504 2000-01-04  51.9880 2015-01-05   \n",
       "2 2013-01-04  58.41 2000-01-05  42.9650 2000-01-05  53.7247 2015-01-06   \n",
       "3 2013-01-07  59.14 2000-01-06  43.8404 2000-01-06  53.1085 2015-01-07   \n",
       "4 2013-01-08  59.74 2000-01-07  44.4786 2000-01-07  52.7163 2015-01-08   \n",
       "\n",
       "     avgo     date.4      ba  ...  date.1008  667517q  date.1009  300583q  \\\n",
       "0  100.09 2000-01-03  40.188  ... 2000-01-03  59.6250 2000-01-03  84.1250   \n",
       "1   98.49 2000-01-04  40.125  ... 2000-01-04  56.6250 2000-01-04  80.8750   \n",
       "2   96.25 2000-01-05  42.625  ... 2000-01-05  54.1250 2000-01-05  79.9375   \n",
       "3   98.85 2000-01-06  43.063  ... 2000-01-06  53.9375 2000-01-06  80.6250   \n",
       "4  103.79 2000-01-07  44.313  ... 2000-01-07  58.0000 2000-01-07  80.4375   \n",
       "\n",
       "   date.1010  285939q  date.1011  1727044d  date.1012  827663q  \n",
       "0 2000-01-03  44.0625 2000-01-03   63.8125 2000-01-03  86.0000  \n",
       "1 2000-01-04  43.5000 2000-01-04   64.6875 2000-01-04  79.6250  \n",
       "2 2000-01-05  44.1875 2000-01-05   65.5000 2000-01-05  77.1875  \n",
       "3 2000-01-06  47.2500 2000-01-06   65.7500        NaT      NaN  \n",
       "4 2000-01-07  49.9375 2000-01-07   65.7500        NaT      NaN  \n",
       "\n",
       "[5 rows x 2026 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tick_df(x, close, split=pd.to_datetime('2017-01-01')):\n",
    "    \"\"\"\n",
    "    Identifies and splits data into 'train' and 'test' parts\n",
    "    \n",
    "    split - date to split into 'test' and 'train' parts\n",
    "    \"\"\"\n",
    "    \n",
    "    tick_df = close.iloc[:,x:x+2]\n",
    "    tick = tick_df.columns[1]\n",
    "    tick_df.columns = ['date', tick]\n",
    "    tick_df = tick_df.set_index('date').dropna()\n",
    "    train = tick_df.loc[:split]\n",
    "    test = tick_df.loc[split-pd.Timedelta(100, 'D'):]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40c7ef73f6c4969954d5ca85c24a9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1013.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "\n",
    "train_df = {}\n",
    "test_df = {}\n",
    "split = pd.to_datetime('2019-03-01')\n",
    "\n",
    "for _ in tqdm_notebook(range(int(close.shape[1]/2))):\n",
    "    \n",
    "    tick = close.iloc[:,x+1].name\n",
    "    if close[tick].dropna().shape[0] == 0:\n",
    "        # some are empty, these are ignored\n",
    "        x+=2\n",
    "        continue\n",
    "    else:\n",
    "        train_df[tick], test_df[tick] = get_tick_df(x, close=close, split=split)\n",
    "        x+=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def ema_rsi(series, a):\n",
    "    \"\"\"\n",
    "    numba-accelerated loop to calculate EMA/Wilder rsi\n",
    "    series - np.array of values, not pd.Series!\n",
    "    a - alpha, or decay parameter of RSI calculation\n",
    "    \"\"\"\n",
    "    prev = series[0]\n",
    "    ema_series = [prev]\n",
    "    \n",
    "    for v in series[1:]:\n",
    "        new_val = a*v + (1-a)*prev\n",
    "        ema_series.append( new_val )\n",
    "        prev = new_val\n",
    "    \n",
    "    return ema_series\n",
    "\n",
    "def rsi(frame, days=14, method='ws'):\n",
    "    \"\"\"\n",
    "    calculates rsi series based on provided parameters\n",
    "    \n",
    "    days - period to calculate the RSI\n",
    "    method - 'ws' (Wilder'), 'sma' (Simple Moving Average), 'ema' (Exponential Moving Average)\n",
    "    \"\"\"\n",
    "    tick = frame.columns[0]\n",
    "    frame['change'] = frame[tick] - frame[tick].shift(1)\n",
    "    frame['up_move'] = np.where( frame['change'] > 0, frame['change'], 0 )\n",
    "    frame['down_move'] = np.abs(np.where( frame['change'] < 0, frame['change'], 0 ))\n",
    "    \n",
    "    if method == 'sma':\n",
    "        frame['avg_up'] = frame['up_move'].rolling(days).mean()\n",
    "        frame['avg_down'] = frame['down_move'].rolling(days).mean()\n",
    "        \n",
    "    elif method == 'ema':\n",
    "        alpha = 2/(days+1)\n",
    "        frame['avg_up'] = ema_rsi( frame['up_move'].values, alpha )\n",
    "        frame['avg_down'] = ema_rsi( frame['down_move'].values, alpha )\n",
    "    \n",
    "    else:\n",
    "        alpha = 1/days\n",
    "        frame['avg_up'] = ema_rsi( frame['up_move'].values, alpha )\n",
    "        frame['avg_down'] = ema_rsi( frame['down_move'].values, alpha )\n",
    "    \n",
    "    frame['rs'] = frame['avg_up']/frame['avg_down']\n",
    "    frame['rsi'] = 100 - 100/(1+frame['rs'])\n",
    "    frame['rsi'].iloc[:days] = np.nan\n",
    "    \n",
    "    return frame['rsi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stock_history():\n",
    "    \n",
    "    def __init__(self, df, rsi_days=14, calc_type='ws'):\n",
    "        \"\"\"\n",
    "        Calculates rsi for this particular stock\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.tick = df.columns[0]\n",
    "        self.df['rsi'] = rsi(self.df[[self.tick]], days=rsi_days, method=calc_type)\n",
    "\n",
    "    def get_signals(self, **key_args):\n",
    "        \"\"\"\n",
    "        calculates signals for the stock with given keywords\n",
    "        and then calculates geometric mean of trades' return \n",
    "        \n",
    "        fwd - holding period after purchasing a stock\n",
    "        low - minimum period after previous low to find a new low in days\n",
    "        high - maximum period after previous low to find a new low in days\n",
    "        step - how often to look for lower low between 'low' and 'high'\n",
    "        rsi1 - maximum RSI value during the first low\n",
    "        rsi2 - maximum RSI value during the second low\n",
    "        rsi_chng - minimum rsi increase from first to second low\n",
    "                   Attempts to find an increase in RSI while the price goes further down\n",
    "        price_chng - maximum price change from first to second low\n",
    "                     Attempts to find an increase in price while the RSI goes up\n",
    "        threshold - minimum number of signals required to consider this a True buy recommendation\n",
    "                    Maximum number of signals is int((high-low)/step), so there can be more than 1 signal in a single day.\n",
    "                    This threshold may decrease the algorithm's false positives. \n",
    "        \"\"\"\n",
    "        \n",
    "        #### uses default kwargs if not all are provided\n",
    "        kwargs = {\n",
    "            'fwd': 5,\n",
    "            'low': 5,\n",
    "            'high': 21,\n",
    "            'step': 5,\n",
    "            'rsi1': 30,\n",
    "            'rsi2': 35,\n",
    "            'rsi_chng': 0,\n",
    "            'price_chng': -0.01,\n",
    "            'threshold': 2\n",
    "        }\n",
    "        \n",
    "        for k, v in key_args.items():\n",
    "            if k in kwargs.keys():\n",
    "                kwargs[k] = v\n",
    "                \n",
    "\n",
    "        self.df['signal'] = 0\n",
    "        self.df['fwd'] = self.df[self.tick].shift(-kwargs['fwd'])/self.df[self.tick]-1\n",
    "\n",
    "        for x in range(kwargs['low'], kwargs['high'], kwargs['step']):\n",
    "            \n",
    "            self.df['d'+str(x)] = self.df[self.tick]/self.df[self.tick].shift(x)-1\n",
    "            self.df['r'+str(x)] = self.df['rsi']-self.df['rsi'].shift(x)\n",
    "            self.df['r_'+str(x)] = self.df['rsi'].shift(x)\n",
    "            \n",
    "            self.df['signal'] = np.where( (self.df.rsi <= kwargs['rsi2']) & \n",
    "                                         (self.df['r_'+str(x)] <= kwargs['rsi1']) & \n",
    "                                           (self.df['r'+str(x)] > kwargs['rsi_chng']) & \n",
    "                                         (self.df['d'+str(x)] < kwargs['price_chng']),\n",
    "                                   self.df['signal'] + 1, self.df['signal'])\n",
    "        \n",
    "        self.geoslice = self.df[self.df.signal >= kwargs['threshold']][[self.tick, 'rsi', 'signal', 'fwd']]\n",
    "        self.geoslice.columns = ['tick', 'rsi', 'signal', 'fwd']\n",
    "        self.geoslice['tick'] = self.tick\n",
    "        self.geomean = np.prod(self.df[self.df.signal >= kwargs['threshold']]['fwd']+1)-1\n",
    "        self.count = self.df[self.df.signal >= kwargs['threshold']].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04731301257959908 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tick</th>\n",
       "      <th>rsi</th>\n",
       "      <th>signal</th>\n",
       "      <th>fwd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-02-07</th>\n",
       "      <td>aa</td>\n",
       "      <td>29.944085</td>\n",
       "      <td>2</td>\n",
       "      <td>0.060551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-06-24</th>\n",
       "      <td>aa</td>\n",
       "      <td>30.287920</td>\n",
       "      <td>2</td>\n",
       "      <td>0.071428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-15</th>\n",
       "      <td>aa</td>\n",
       "      <td>30.815151</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.148973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-10-11</th>\n",
       "      <td>aa</td>\n",
       "      <td>24.744055</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-10-12</th>\n",
       "      <td>aa</td>\n",
       "      <td>23.878613</td>\n",
       "      <td>2</td>\n",
       "      <td>0.044473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-10-14</th>\n",
       "      <td>aa</td>\n",
       "      <td>31.049742</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-13</th>\n",
       "      <td>aa</td>\n",
       "      <td>25.808165</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.102024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-16</th>\n",
       "      <td>aa</td>\n",
       "      <td>26.224120</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-20</th>\n",
       "      <td>aa</td>\n",
       "      <td>28.471893</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.271555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-21</th>\n",
       "      <td>aa</td>\n",
       "      <td>27.969231</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.112758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-22</th>\n",
       "      <td>aa</td>\n",
       "      <td>24.990539</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-23</th>\n",
       "      <td>aa</td>\n",
       "      <td>24.092145</td>\n",
       "      <td>2</td>\n",
       "      <td>0.146144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-24</th>\n",
       "      <td>aa</td>\n",
       "      <td>23.112826</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-27</th>\n",
       "      <td>aa</td>\n",
       "      <td>22.484968</td>\n",
       "      <td>2</td>\n",
       "      <td>0.314157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-28</th>\n",
       "      <td>aa</td>\n",
       "      <td>31.859727</td>\n",
       "      <td>3</td>\n",
       "      <td>0.156774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-29</th>\n",
       "      <td>aa</td>\n",
       "      <td>33.695992</td>\n",
       "      <td>3</td>\n",
       "      <td>0.058296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-11-06</th>\n",
       "      <td>aa</td>\n",
       "      <td>33.466856</td>\n",
       "      <td>2</td>\n",
       "      <td>0.091619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-03-09</th>\n",
       "      <td>aa</td>\n",
       "      <td>34.707303</td>\n",
       "      <td>2</td>\n",
       "      <td>0.135438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-23</th>\n",
       "      <td>aa</td>\n",
       "      <td>34.899742</td>\n",
       "      <td>2</td>\n",
       "      <td>0.058219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-31</th>\n",
       "      <td>aa</td>\n",
       "      <td>34.510391</td>\n",
       "      <td>2</td>\n",
       "      <td>0.058051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-26</th>\n",
       "      <td>aa</td>\n",
       "      <td>25.132111</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.056458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-10</th>\n",
       "      <td>aa</td>\n",
       "      <td>19.303460</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.013173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-13</th>\n",
       "      <td>aa</td>\n",
       "      <td>28.022706</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.057300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-14</th>\n",
       "      <td>aa</td>\n",
       "      <td>27.189917</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.050141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-15</th>\n",
       "      <td>aa</td>\n",
       "      <td>24.104771</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.054871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-16</th>\n",
       "      <td>aa</td>\n",
       "      <td>23.252192</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.052329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-17</th>\n",
       "      <td>aa</td>\n",
       "      <td>22.960665</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.064824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-21</th>\n",
       "      <td>aa</td>\n",
       "      <td>20.647686</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.035189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-22</th>\n",
       "      <td>aa</td>\n",
       "      <td>17.887873</td>\n",
       "      <td>2</td>\n",
       "      <td>0.017016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-23</th>\n",
       "      <td>aa</td>\n",
       "      <td>17.571590</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-28</th>\n",
       "      <td>aa</td>\n",
       "      <td>25.528840</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.014183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-30</th>\n",
       "      <td>aa</td>\n",
       "      <td>32.890431</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.007015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-31</th>\n",
       "      <td>aa</td>\n",
       "      <td>31.133881</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.046606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-03</th>\n",
       "      <td>aa</td>\n",
       "      <td>27.792307</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-04</th>\n",
       "      <td>aa</td>\n",
       "      <td>30.917450</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.025694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-05</th>\n",
       "      <td>aa</td>\n",
       "      <td>31.974323</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.025615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-07</th>\n",
       "      <td>aa</td>\n",
       "      <td>29.179392</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tick        rsi  signal       fwd\n",
       "date                                        \n",
       "2000-02-07   aa  29.944085       2  0.060551\n",
       "2002-06-24   aa  30.287920       2  0.071428\n",
       "2002-07-15   aa  30.815151       2 -0.148973\n",
       "2005-10-11   aa  24.744055       2  0.018818\n",
       "2005-10-12   aa  23.878613       2  0.044473\n",
       "2005-10-14   aa  31.049742       2  0.016543\n",
       "2008-10-13   aa  25.808165       2 -0.102024\n",
       "2008-10-16   aa  26.224120       2 -0.181818\n",
       "2008-10-20   aa  28.471893       3 -0.271555\n",
       "2008-10-21   aa  27.969231       2 -0.112758\n",
       "2008-10-22   aa  24.990539       2  0.059885\n",
       "2008-10-23   aa  24.092145       2  0.146144\n",
       "2008-10-24   aa  23.112826       2  0.222106\n",
       "2008-10-27   aa  22.484968       2  0.314157\n",
       "2008-10-28   aa  31.859727       3  0.156774\n",
       "2008-10-29   aa  33.695992       3  0.058296\n",
       "2008-11-06   aa  33.466856       2  0.091619\n",
       "2009-03-09   aa  34.707303       2  0.135438\n",
       "2011-08-23   aa  34.899742       2  0.058219\n",
       "2015-03-31   aa  34.510391       2  0.058051\n",
       "2015-06-26   aa  25.132111       2 -0.056458\n",
       "2015-07-10   aa  19.303460       2 -0.013173\n",
       "2015-07-13   aa  28.022706       4 -0.057300\n",
       "2015-07-14   aa  27.189917       4 -0.050141\n",
       "2015-07-15   aa  24.104771       2 -0.054871\n",
       "2015-07-16   aa  23.252192       2 -0.052329\n",
       "2015-07-17   aa  22.960665       4 -0.064824\n",
       "2015-07-21   aa  20.647686       3 -0.035189\n",
       "2015-07-22   aa  17.887873       2  0.017016\n",
       "2015-07-23   aa  17.571590       2  0.002008\n",
       "2015-07-28   aa  25.528840       3 -0.014183\n",
       "2015-07-30   aa  32.890431       3 -0.007015\n",
       "2015-07-31   aa  31.133881       3 -0.046606\n",
       "2015-08-03   aa  27.792307       2  0.045643\n",
       "2015-08-04   aa  30.917450       4 -0.025694\n",
       "2015-08-05   aa  31.974323       3 -0.025615\n",
       "2015-08-07   aa  29.179392       3  0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Checking if stuff works:\n",
    "\n",
    "ticker = 'aa'\n",
    "itick = Stock_history(train_df[ticker])\n",
    "itick.get_signals()\n",
    "print(itick.geomean, itick.count)\n",
    "itick.geoslice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a Bayesian optimizatio of parameters listed in 'get_signals' method of Stock_history class. \n",
    "It attempts to find the best parameters withing some bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [\n",
    "    \n",
    "    Integer(2, 15, name='fwd'),\n",
    "    Integer(3, 12, name='low'),\n",
    "    Integer(12, 50, name='high'),\n",
    "    Integer(1, 4, name='step'),  \n",
    "    Integer(30, 40, name='rsi1'),\n",
    "    Integer(20, 30, name='rsi2'),   \n",
    "    Real(0, 2, prior='uniform', name='rsi_chng'),    \n",
    "    Real(-0.05, 0, prior='uniform', name='price_chng'),   \n",
    "    Integer(1, 4, name='threshold'),\n",
    "]\n",
    "\n",
    "default_params = {\n",
    "    'fwd': 5,\n",
    "    'low': 5,\n",
    "    'high': 21,\n",
    "    'step': 5,\n",
    "    'rsi1': 30,\n",
    "    'rsi2': 35,\n",
    "    'rsi_chng': 0,\n",
    "    'price_chng': -0.01,\n",
    "    'threshold': 2\n",
    "}\n",
    "\n",
    "@use_named_args(search_space)\n",
    "def assess_kwargs(**kwargs):\n",
    "    \"\"\"\n",
    "    Assesses parameters and returns a value based on the geometric mean of returns divided\n",
    "    by the standard deviation of returns to penalize for volatility.\n",
    "    \n",
    "    Low number of predictions (i.e. less than 500) can be additionally penalized. \n",
    "    \"\"\"\n",
    "    print(kwargs)\n",
    "    stocks = {}\n",
    "    slices = {}\n",
    "\n",
    "    for k, v in tqdm_notebook(train_df.items()):\n",
    "\n",
    "        stocks[k] = Stock_history(v)\n",
    "        stocks[k].get_signals(**kwargs)\n",
    "        slices[k] = stocks[k].geoslice\n",
    "\n",
    "    geoslice = pd.concat(slices.values()).sort_index()\n",
    "    geoslice['date_'] = geoslice.index\n",
    "    geoslice = geoslice.sort_values(by=['date', 'signal']).drop_duplicates(subset=['date_'])\n",
    "    \n",
    "    #Full penalty for extremely low number of predictions\n",
    "    if geoslice.shape[0] < 50:\n",
    "        return 0\n",
    "    #Proportionally penalizes for low number of predictions\n",
    "    elif geoslice.shape[0] < 500:\n",
    "        return -geoslice['fwd'].mean()/geoslice['fwd'].std() * geoslice.shape[0]/500\n",
    "    else:\n",
    "        return -geoslice['fwd'].mean()/geoslice['fwd'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bayesian optimization process to find optimal parameters.\n",
    "\n",
    "Saves them to disk afterwards for future use.\n",
    "\"\"\"\n",
    "\n",
    "result = gp_minimize(assess_kwargs, search_space, random_state=17, n_calls=50, verbose=True, n_initial_points=20)\n",
    "opt_params = dict(zip(default_params.keys(), result.x))\n",
    "\n",
    "with open('mid_rsi_params.dict', 'wb') as config_dictionary_file:\n",
    " \n",
    "    pickle.dump(opt_params, config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing parameters on test data. \n",
    "\"\"\"\n",
    "\n",
    "stocks = {}\n",
    "slices = {}\n",
    "\n",
    "for k, v in tqdm_notebook(test_df.items()):\n",
    "\n",
    "    stocks[k] = Stock_history(v)\n",
    "    stocks[k].get_signals(**opt_params)\n",
    "    slices[k] = stocks[k].geoslice\n",
    "\n",
    "geoslice = pd.concat(slices.values()).sort_index()\n",
    "geoslice['date_'] = geoslice.index\n",
    "geoslice = geoslice.sort_values(by=['date', 'signal']).drop_duplicates(subset=['date_'])\n",
    "\n",
    "print(geoslice['fwd'].mean(), geoslice['fwd'].median(), geoslice['fwd'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
