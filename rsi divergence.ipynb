{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from numba import jit\n",
    "import pickle\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data provided must be in the following form:\n",
    "\n",
    "datesA closeA datesB closeB datesC closeC ...\n",
    "\n",
    "This method prevents survivorship bias if one just selected current members of S&P 500 index (or any other index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = pd.read_parquet('spx_close.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tick_df(x, close, split=pd.to_datetime('2017-01-01')):\n",
    "    \"\"\"\n",
    "    Identifies and splits data into 'train' and 'test' parts\n",
    "    \n",
    "    split - date to split into 'test' and 'train' parts\n",
    "    \"\"\"\n",
    "    \n",
    "    tick_df = close.iloc[:,x:x+2]\n",
    "    tick = tick_df.columns[1]\n",
    "    tick_df.columns = ['date', tick]\n",
    "    tick_df = tick_df.set_index('date').dropna()\n",
    "    train = tick_df.loc[:split]\n",
    "    test = tick_df.loc[split-pd.Timedelta(100, 'D'):]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "train_df = {}\n",
    "test_df = {}\n",
    "split = pd.to_datetime('2019-03-01')\n",
    "\n",
    "for _ in tqdm_notebook(range(int(close.shape[1]/2))):\n",
    "    \n",
    "    tick = close.iloc[:,x+1].name\n",
    "    if close[tick].dropna().shape[0] == 0:\n",
    "        # some are empty, these are ignored\n",
    "        x+=2\n",
    "        continue\n",
    "    else:\n",
    "        train_df[tick], test_df[tick] = get_tick_df(x, close=close, split=split)\n",
    "        x+=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def ema_rsi(series, a):\n",
    "    \"\"\"\n",
    "    numba-accelerated loop to calculate EMA/Wilder rsi\n",
    "    series - np.array of values, not pd.Series!\n",
    "    a - alpha, or decay parameter of RSI calculation\n",
    "    \"\"\"\n",
    "    prev = series[0]\n",
    "    ema_series = [prev]\n",
    "    \n",
    "    for v in series[1:]:\n",
    "        new_val = a*v + (1-a)*prev\n",
    "        ema_series.append( new_val )\n",
    "        prev = new_val\n",
    "    \n",
    "    return ema_series\n",
    "\n",
    "def rsi(frame, days=14, method='ws'):\n",
    "    \"\"\"\n",
    "    calculates rsi series based on provided parameters\n",
    "    \n",
    "    days - period to calculate the RSI\n",
    "    method - 'ws' (Wilder'), 'sma' (Simple Moving Average), 'ema' (Exponential Moving Average)\n",
    "    \"\"\"\n",
    "    tick = frame.columns[0]\n",
    "    frame['change'] = frame[tick] - frame[tick].shift(1)\n",
    "    frame['up_move'] = np.where( frame['change'] > 0, frame['change'], 0 )\n",
    "    frame['down_move'] = np.abs(np.where( frame['change'] < 0, frame['change'], 0 ))\n",
    "    \n",
    "    if method == 'sma':\n",
    "        frame['avg_up'] = frame['up_move'].rolling(days).mean()\n",
    "        frame['avg_down'] = frame['down_move'].rolling(days).mean()\n",
    "        \n",
    "    elif method == 'ema':\n",
    "        alpha = 2/(days+1)\n",
    "        frame['avg_up'] = ema_rsi( frame['up_move'].values, alpha )\n",
    "        frame['avg_down'] = ema_rsi( frame['down_move'].values, alpha )\n",
    "    \n",
    "    else:\n",
    "        alpha = 1/days\n",
    "        frame['avg_up'] = ema_rsi( frame['up_move'].values, alpha )\n",
    "        frame['avg_down'] = ema_rsi( frame['down_move'].values, alpha )\n",
    "    \n",
    "    frame['rs'] = frame['avg_up']/frame['avg_down']\n",
    "    frame['rsi'] = 100 - 100/(1+frame['rs'])\n",
    "    frame['rsi'].iloc[:days] = np.nan\n",
    "    \n",
    "    return frame['rsi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stock_history():\n",
    "    \n",
    "    def __init__(self, df, rsi_days=14, calc_type='ws'):\n",
    "        \"\"\"\n",
    "        Calculates rsi for this particular stock\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.tick = df.columns[0]\n",
    "        self.df['rsi'] = rsi(self.df[[self.tick]], days=rsi_days, method=calc_type)\n",
    "\n",
    "    def get_signals(self, **key_args):\n",
    "        \"\"\"\n",
    "        calculates signals for the stock with given keywords\n",
    "        and then calculates geometric mean of trades' return \n",
    "        \n",
    "        fwd - holding period after purchasing a stock\n",
    "        low - minimum period after previous low to find a new low in days\n",
    "        high - maximum period after previous low to find a new low in days\n",
    "        step - how often to look for lower low between 'low' and 'high'\n",
    "        rsi1 - maximum RSI value during the first low\n",
    "        rsi2 - maximum RSI value during the second low\n",
    "        rsi_chng - minimum rsi increase from first to second low\n",
    "                   Attempts to find an increase in RSI while the price goes further down\n",
    "        price_chng - maximum price change from first to second low\n",
    "                     Attempts to find an increase in price while the RSI goes up\n",
    "        threshold - minimum number of signals required to consider this a True buy recommendation\n",
    "                    Maximum number of signals is int((high-low)/step), so there can be more than 1 signal in a single day.\n",
    "                    This threshold may decrease the algorithm's false positives. \n",
    "        \"\"\"\n",
    "        \n",
    "        #### uses default kwargs if not all are provided\n",
    "        kwargs = {\n",
    "            'fwd': 5,\n",
    "            'low': 5,\n",
    "            'high': 21,\n",
    "            'step': 5,\n",
    "            'rsi1': 30,\n",
    "            'rsi2': 35,\n",
    "            'rsi_chng': 0,\n",
    "            'price_chng': -0.01,\n",
    "            'threshold': 2\n",
    "        }\n",
    "        \n",
    "        for k, v in key_args.items():\n",
    "            if k in kwargs.keys():\n",
    "                kwargs[k] = v\n",
    "                \n",
    "\n",
    "        self.df['signal'] = 0\n",
    "        self.df['fwd'] = self.df[self.tick].shift(-kwargs['fwd'])/self.df[self.tick]-1\n",
    "\n",
    "        for x in range(kwargs['low'], kwargs['high'], kwargs['step']):\n",
    "            \n",
    "            self.df['d'+str(x)] = self.df[self.tick]/self.df[self.tick].shift(x)-1\n",
    "            self.df['r'+str(x)] = self.df['rsi']-self.df['rsi'].shift(x)\n",
    "            self.df['r_'+str(x)] = self.df['rsi'].shift(x)\n",
    "            \n",
    "            self.df['signal'] = np.where( (self.df.rsi <= kwargs['rsi2']) & \n",
    "                                         (self.df['r_'+str(x)] <= kwargs['rsi1']) & \n",
    "                                           (self.df['r'+str(x)] > kwargs['rsi_chng']) & \n",
    "                                         (self.df['d'+str(x)] < kwargs['price_chng']),\n",
    "                                   self.df['signal'] + 1, self.df['signal'])\n",
    "        \n",
    "        self.geoslice = self.df[self.df.signal >= kwargs['threshold']][[self.tick, 'rsi', 'signal', 'fwd']]\n",
    "        self.geoslice.columns = ['tick', 'rsi', 'signal', 'fwd']\n",
    "        self.geoslice['tick'] = self.tick\n",
    "        self.geomean = np.prod(self.df[self.df.signal >= kwargs['threshold']]['fwd']+1)-1\n",
    "        self.count = self.df[self.df.signal >= kwargs['threshold']].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Checking if stuff works:\n",
    "\n",
    "ticker = 'aa'\n",
    "itick = Stock_history(train_df[ticker])\n",
    "itick.get_signals()\n",
    "print(itick.geomean, itick.count)\n",
    "itick.geoslice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a Bayesian optimizatio of parameters listed in 'get_signals' method of Stock_history class. \n",
    "It attempts to find the best parameters withing some bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [\n",
    "    \n",
    "    Integer(2, 15, name='fwd'),\n",
    "    Integer(3, 12, name='low'),\n",
    "    Integer(12, 50, name='high'),\n",
    "    Integer(1, 4, name='step'),  \n",
    "    Integer(30, 40, name='rsi1'),\n",
    "    Integer(20, 30, name='rsi2'),   \n",
    "    Real(0, 2, prior='uniform', name='rsi_chng'),    \n",
    "    Real(-0.05, 0, prior='uniform', name='price_chng'),   \n",
    "    Integer(1, 4, name='threshold'),\n",
    "]\n",
    "\n",
    "default_params = {\n",
    "    'fwd': 5,\n",
    "    'low': 5,\n",
    "    'high': 21,\n",
    "    'step': 5,\n",
    "    'rsi1': 30,\n",
    "    'rsi2': 35,\n",
    "    'rsi_chng': 0,\n",
    "    'price_chng': -0.01,\n",
    "    'threshold': 2\n",
    "}\n",
    "\n",
    "@use_named_args(search_space)\n",
    "def assess_kwargs(**kwargs):\n",
    "    \"\"\"\n",
    "    Assesses parameters and returns a value based on the geometric mean of returns divided\n",
    "    by the standard deviation of returns to penalize for volatility.\n",
    "    \n",
    "    Low number of predictions (i.e. less than 500) can be additionally penalized. \n",
    "    \"\"\"\n",
    "    print(kwargs)\n",
    "    stocks = {}\n",
    "    slices = {}\n",
    "\n",
    "    for k, v in tqdm_notebook(train_df.items()):\n",
    "\n",
    "        stocks[k] = Stock_history(v)\n",
    "        stocks[k].get_signals(**kwargs)\n",
    "        slices[k] = stocks[k].geoslice\n",
    "\n",
    "    geoslice = pd.concat(slices.values()).sort_index()\n",
    "    geoslice['date_'] = geoslice.index\n",
    "    geoslice = geoslice.sort_values(by=['date', 'signal']).drop_duplicates(subset=['date_'])\n",
    "    \n",
    "    #Full penalty for extremely low number of predictions\n",
    "    if geoslice.shape[0] < 50:\n",
    "        return 0\n",
    "    #Proportionally penalizes for low number of predictions\n",
    "    elif geoslice.shape[0] < 500:\n",
    "        return -geoslice['fwd'].mean()/geoslice['fwd'].std() * geoslice.shape[0]/500\n",
    "    else:\n",
    "        return -geoslice['fwd'].mean()/geoslice['fwd'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bayesian optimization process to find optimal parameters.\n",
    "\n",
    "Saves them to disk afterwards for future use.\n",
    "\"\"\"\n",
    "\n",
    "result = gp_minimize(assess_kwargs, search_space, random_state=17, n_calls=50, verbose=True, n_initial_points=20)\n",
    "opt_params = dict(zip(default_params.keys(), result.x))\n",
    "\n",
    "with open('mid_rsi_params.dict', 'wb') as config_dictionary_file:\n",
    " \n",
    "    pickle.dump(opt_params, config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing parameters on test data. \n",
    "\"\"\"\n",
    "\n",
    "stocks = {}\n",
    "slices = {}\n",
    "\n",
    "for k, v in tqdm_notebook(test_df.items()):\n",
    "\n",
    "    stocks[k] = Stock_history(v)\n",
    "    stocks[k].get_signals(**opt_params)\n",
    "    slices[k] = stocks[k].geoslice\n",
    "\n",
    "geoslice = pd.concat(slices.values()).sort_index()\n",
    "geoslice['date_'] = geoslice.index\n",
    "geoslice = geoslice.sort_values(by=['date', 'signal']).drop_duplicates(subset=['date_'])\n",
    "\n",
    "print(geoslice['fwd'].mean(), geoslice['fwd'].median(), geoslice['fwd'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
